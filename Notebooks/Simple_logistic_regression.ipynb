{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression \n",
    "\n",
    "- Is a classifier\n",
    "\n",
    "- How is it different from SVM?\n",
    "\n",
    "    - SVM **can not** tell us how probable I am healthy. \n",
    "    - For example, if my Serotonin is 3 and my Dopamine is 6, what is the chance that I would be considered as healthy\n",
    "   90 percent or 60 percent or etc.\n",
    "    \n",
    "- Logistic Regression can do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Watch a video about Logistic Regression\n",
    "\n",
    "Lets watch this video: https://www.youtube.com/watch?v=yIYKR4sgzI8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Dataset We use for Logistic Regression\n",
    "\n",
    "- Pima Indian Diabetes\n",
    "\n",
    "- The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset\n",
    "\n",
    "- In particular, all patients here are females at least 21 years old of Pima Indian heritage\n",
    "\n",
    "- Labels: 1: diabetes, 0: no diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Obtain confusion matrix, accuracy, precision, recall for pima Diabetes dataset\n",
    "\n",
    "Steps:\n",
    "\n",
    "1- Load the dataset: `pd.read_csv('diabetes.csv')`\n",
    "\n",
    "2- Use these features: `feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']`\n",
    "\n",
    "3- Split the data to train and test: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)`\n",
    "\n",
    "4- Instantiate logistic regression model\n",
    "\n",
    "5- Obtain the statistics of `y_test`\n",
    "\n",
    "6- Obtain the confuction matrix\n",
    "\n",
    "https://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pima = pd.read_csv('diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "# X is a matrix,access the features we want in feature_cols\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Check the size of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "576.0\n",
      "192\n",
      "192.0\n"
     ]
    }
   ],
   "source": [
    "# check the size of y_train\n",
    "\n",
    "print(len(y_train))\n",
    "print(0.75*len(pima))\n",
    "\n",
    "print(len(y_test))\n",
    "print(0.25*len(pima))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build our classifier model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.values.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How many of samples in y_train have diabetes how many not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.hist(y_test, bins=20)\n",
    "plt.show()\n",
    "\n",
    "y_test_pd_series = pd.Series(y_test)\n",
    "y_test_pd_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Write a function that calculates:\n",
    "\n",
    "- How many of 0 (no diabetes) in y_test is predicted correctly as 0 (no diabetes) in y_pred?\n",
    "\n",
    "- How many of 0 (no diabetes) in y_test is predicted incorrectly as 1 (diabetes) in y_pred?\n",
    "\n",
    "- How many of 1 (diabetes) in y_test is predicted incorrectly as 0 (no diabetes) in y_pred?\n",
    "\n",
    "- How many of 1 (diabetes) in y_test is predicted correctly 1 (diabetes) in y_pred?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118.  12.]\n",
      " [ 47.  15.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def comp_yt_yp(y_test, y_predict):\n",
    "    conf_matrix  = np.zeros((2, 2))\n",
    "    for m in [0, 1]:\n",
    "        for n in [0, 1]:\n",
    "            c = 0\n",
    "            for (i, j) in zip(y_test, y_predict):\n",
    "                if (i == m) & (j == n):\n",
    "                        c += 1\n",
    "            conf_matrix[m, n] = c \n",
    "    return conf_matrix\n",
    "\n",
    "print(comp_yt_yp(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Easier way to compute elements of Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic terminology\n",
    "\n",
    "True Positives (TP): we correctly predicted that they do have diabetes: 15\n",
    "\n",
    "True Negatives (TN): we correctly predicted that they don't have diabetes: 118\n",
    "\n",
    "False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\"): 12\n",
    "\n",
    "False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\"): 47\n",
    "\n",
    "<img src=\"Images/confusion_matrix.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The difference between `.predict()` and `.predict_proba` for a classifier\n",
    "\n",
    "Apply these two methods to Pima Indian Diabetes dataset\n",
    "\n",
    "https://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
