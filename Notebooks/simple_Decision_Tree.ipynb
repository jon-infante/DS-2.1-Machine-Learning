{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/slide_1.png\" width=\"700\" height=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/slide_2.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- Decision Trees are considered one of the most mature, traditional algorithms in predictive analytics\n",
    "\n",
    "- They are most likely used for classification problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why and where we need Decision Tree ?\n",
    "\n",
    "- When features are Categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Examples of Decision Tree\n",
    "\n",
    "- You’ll take a small dataset and see if you can learn anything from it\n",
    "\n",
    "- You’ll see if a decision tree can give you any insight as to how the eye doctor prescribes contact lenses\n",
    "\n",
    "- You can predict the type of lenses people will use and understand the underlying processes with a decision tree\n",
    "\n",
    "- Predict does a player plays tennis outside based on weather conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lens Dataset\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    " 3 Classes\n",
    "\n",
    " 1 : the patient should be fitted with hard contact lenses,\n",
    "\n",
    " 2 : the patient should be fitted with soft contact lenses,\n",
    "\n",
    " 3 : the patient should not be fitted with contact lenses.\n",
    " \n",
    "4 Features\n",
    "\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "<img src=\"Images/lens_data.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/lens_DT.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The root and the leafs for Decision Tree are obtained based on \n",
    "\n",
    "- Conditional Probability\n",
    "\n",
    "- Entropy\n",
    "\n",
    "- Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the entropy for a fair coin\n",
    "\n",
    "Entropy shows the uncertainy about a random variable\n",
    "\n",
    "Show that the fair coin has the largest entropy (uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H\n",
    "    \n",
    "p = [.5, .5]\n",
    "entropy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change p (probability of head and tale) and plot entropy for different p\n",
    "\n",
    "<img src=\"Images/coin_entropy.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    " The fair coin has the highest entropy which means a fair coin has the highest uncertain result when toss a coin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let build a Decision Tree for Tennis Data\n",
    "\n",
    "The following table informs about decision making factors to play tennis at outside based on 14 days data, for different weather conditions\n",
    "\n",
    "<img src=\"Images/dst_1.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the following quantitites:\n",
    "\n",
    "- Obtain the entropy of `PlayTennis` (Decision) column. Hint: p = [9/14, 5/14] which represents the probability that a player plays tennis or not\n",
    "\n",
    "`Entropy(Decision) = – (9/14) . log2(9/14) – (5/14) . log2(5/14) = 0.940`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wind factor on Decision\n",
    "\n",
    "    - Obtain the entropy of conditional probability `p(PlayTennis | Wind = Weak) = [2/8, 6/8]`\n",
    "    \n",
    "    - <img src=\"Images/weak_wind_decision.png\" width=\"400\" height=\"400\">\n",
    "    \n",
    "    - Obtain the entropy of conditional probability `p(PlayTennis | Wind = Strong) = [3/6, 3/6]`\n",
    "    \n",
    "    -  <img src=\"Images/strong_wind_decision.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Information Gain Between PlayTennis (Decision) and Wind\n",
    "\n",
    "- What is the probability that wind be weak? Hint = Count how many weak wind we have devide over how many sample we have.\n",
    "\n",
    "`p(Wind = Weak) = 8/ 14`\n",
    "\n",
    "`p(Wind = Strong) = 6/ 14`\n",
    "\n",
    "- Information Gain(Decision, Wind) = \n",
    "\n",
    "`Entropy(Decision) - p(Wind = Weak)Entropy(Decision | Wind = Weak ) - p(Wind = Strong)Entropy(Decision | Wind = Strong )`\n",
    "\n",
    "= 0.048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other factors on Decision column\n",
    "\n",
    "We have applied similar calculation on the other features (columns)\n",
    "\n",
    "1 - Gain(Decision, Wind) = 0.048\n",
    "\n",
    "2 - Gain(Decision, Outlook) = 0.246\n",
    "\n",
    "3 - Gain(Decision, Temperature) = 0.029\n",
    "\n",
    "4 - Gain(Decision, Humidity) = 0.151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see Outlook and Decision has the highest Gain, so Outlook would be the root for the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If keep continuing the calculation of Information Gain between nodes (features), \n",
    "\n",
    "## The tree is built based on the highest Information Gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Build the decision tree with sklearn for tennis dataset\n",
    "\n",
    "#### For Decision Tree Visualization in Python:\n",
    "\n",
    "Packages that are needed:\n",
    "\n",
    "`conda install -c anaconda graphviz`\n",
    "\n",
    "`conda install -c anaconda pydot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "\n",
    "data = pd.read_csv('tennis.txt', delimiter=\"\\t\", header=None, names=['a', 'b', 'c', 'd', 'e'])\n",
    "print(data)\n",
    "\n",
    "data_encoded = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "print(data_encoded)\n",
    "\n",
    "#\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# one_hot_data = pd.get_dummies(data[['a', 'b', 'c', 'd']], drop_first=True)\n",
    "# print(one_hot_data)\n",
    "clf.fit(data_encoded[['a', 'b', 'c', 'd']], data_encoded['e'])\n",
    "\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None, feature_names=['Outlook', 'Temp.', 'Humidity', 'Wind'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png('tennis_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "- A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences\n",
    "\n",
    "- Decision Tree provides an effective method of Decision Making \n",
    "\n",
    "- The best feature of using trees for analytics - easy to interpret and explain to executives\n",
    "\n",
    "- The mechanism behind DT are maximizing information gains while have different options "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- https://sefiks.com/2017/11/20/a-step-by-step-id3-decision-tree-example/\n",
    "\n",
    "- https://heartbeat.fritz.ai/introduction-to-decision-tree-learning-cd604f85e236\n",
    "\n",
    "- https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0161696.g002&size=inline\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
